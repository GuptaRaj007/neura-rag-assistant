# ğŸ§  Neura RAG Assistant

### Prompt Engineering & Retrieval-Augmented Generation (RAG) Mini Project

> A grounded, hallucination-safe policy assistant built with **local LLMs**, **semantic search**, and **iterative prompt design**.

---

## ğŸŒŸ Overview

**Neura RAG Assistant** is a **Retrieval-Augmented Generation (RAG)** system that answers user questions **strictly from company policy documents** (Refund, Cancellation, Shipping, etc.).

It is designed to:

* ğŸ” Retrieve only relevant policy text
* ğŸ“Œ Ground answers in retrieved context
* ğŸš« Avoid hallucinations
* ğŸ§© Use **iteratively improved prompts**
* ğŸ“Š Include a lightweight **evaluation framework**

Built as part of the **AI Engineer Intern â€“ Take Home Assignment**.

---

## ğŸ— Architecture

```
User Question
      â”‚
      â–¼
Retriever (FAISS + Sentence Transformers)
      â”‚
      â–¼
Top-K Relevant Policy Chunks
      â”‚
      â–¼
Prompt Template (PROMPT_V3)
      â”‚
      â–¼
LLM (Local via Ollama)
      â”‚
      â–¼
Final Answer
(Grounded â€¢ Structured â€¢ No Hallucination)
```

---

## ğŸ›  Tech Stack

* **Python**
* **Sentence Transformers** (`all-MiniLM-L6-v2`)
* **FAISS** (vector store)
* **LangChain** (document loading & splitting)
* **Ollama** (local LLM runtime â€“ `llama3`)
* **PyPDF**
* **HuggingFace embeddings**

---

## ğŸš€ Setup Instructions

```bash
git clone https://github.com/GuptaRaj007/neura-rag-assistant.git
cd neura-rag-assistant
python -m venv neura_env
neura_env\Scripts\activate   # Windows
pip install -r requirements.txt
```

Start Ollama:

```bash
ollama run llama3
```

Run the assistant:

```bash
python src/qa.py
```

Run evaluation:

```bash
python src/evaluate.py
```

---

## 1ï¸âƒ£ Data Preparation

### Document Loading

Policy documents are loaded using **LangChain loaders** from the `data/` folder.

### Chunking Strategy

* **Chunk size:** 500 characters
* **Overlap:** 100 characters

**Why?**

* Smaller chunks â†’ better semantic matching
* Overlap preserves sentence continuity
* Prevents splitting policy rules mid-sentence

---

## 2ï¸âƒ£ RAG Pipeline

| Step              | Implementation                           |
| ----------------- | ---------------------------------------- |
| Embeddings        | `sentence-transformers/all-MiniLM-L6-v2` |
| Vector Store      | FAISS                                    |
| Retrieval         | Semantic similarity (Top-K)              |
| Context Injection | Prompt templates                         |
| LLM               | Ollama (`llama3`)                        |

---

## 3ï¸âƒ£ Prompt Engineering (Core Focus)

We iterated through **three prompt versions**:

### ğŸŸ¢ PROMPT_V1 â€“ Basic

```text
Use the following context to answer the question.

Context:
{context}

Question:
{question}
```

---

### ğŸŸ¡ PROMPT_V2 â€“ Improved

```text
You are a policy assistant. Answer ONLY using the provided context.
If the answer is not present, say: "Not available in the provided documents."

Context:
{context}

Question:
{question}

Answer:
```

---

### ğŸ”´ PROMPT_V3 â€“ Final (Production)

```text
You are a strict policy assistant.

Rules:
1. Answer ONLY from the context below.
2. If not found, say: "The information is not available in the provided documents."
3. Quote the policy when possible.
4. Use a clear, structured format.

Context:
{context}

Question:
{question}

Output:
Quote:
- ...

Answer:
...
```

### Why PROMPT_V3 is Better

* ğŸš« Eliminates hallucination
* ğŸ“Œ Forces grounding
* ğŸ§± Structured output
* ğŸ¤ Handles missing info safely

---

## 4ï¸âƒ£ Evaluation

We created **6 test questions**:

| Question                                   | Expected      | Result |
| ------------------------------------------ | ------------- | ------ |
| Can I get a refund after 10 days?          | Not allowed   | âœ…      |
| Can I cancel after shipping?               | Not allowed   | âœ…      |
| How long does international shipping take? | 10â€“15 days    | âœ…      |
| Do you offer free express delivery?        | Not mentioned | âš ï¸     |
| Can I cancel my subscription mid-cycle?    | No refund     | âš ï¸     |
| What is your office address?               | Not mentioned | âœ…      |

### Example Output

```
Q: What is your office address?
Expected: Not mentioned
Model Answer:
The information is not available in the provided documents.
```

---

## 5ï¸âƒ£ Edge Case Handling

| Scenario              | Behavior                |
| --------------------- | ----------------------- |
| No matching policy    | Graceful refusal        |
| Out-of-scope question | No hallucination        |
| Partial information   | Safe, grounded response |

---

## âš– Key Trade-offs

* No reranker â†’ faster, but slightly less precise
* Local LLM â†’ private, but lower fluency
* Small dataset â†’ perfect for demo, not scale

---

## ğŸ”® Future Improvements

* Reranking layer
* JSON schema validation
* Streaming UI
* LangGraph agents
* Logging & tracing

---

## ğŸ’¬ Reflection

**What Iâ€™m Most Proud Of:**
Building a fully grounded RAG system with **prompt iteration and evaluation**, not just a chatbot.

**What Iâ€™d Improve Next:**
Add reranking and automatic response scoring.

---

## ğŸ“ Folder Structure

```
â”œâ”€â”€ data/                 # policy documents
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ load_docs.py
â”‚   â”œâ”€â”€ embed_store.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ prompts.py
â”‚   â”œâ”€â”€ qa.py
â”‚   â””â”€â”€ evaluate.py
```
